<div align="center">
  <img src="images/logo1.png" alt="Promptomatix Logo" width="400"/>
  
  <h1>Promptomatix</h1>
  <h3>A Powerful Framework for LLM Prompt Optimization</h3>
</div>

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.10%2B-brightgreen.svg" alt="Python 3.10+">
  <img src="https://img.shields.io/badge/License-Apache-green.svg" alt="License">
  <a href="https://arxiv.org/abs/2507.14241" target="_blank">
    <img src="https://img.shields.io/badge/arXiv-2507.14241-b31b1b.svg" alt="arXiv">
  </a>
  <a href="docs/API_Reference.md" target="_blank">
    <img src="https://img.shields.io/badge/Documentation-API-blue.svg" alt="API Documentation">
  </a>
</div>

<p align="center">
  <a href="#-overview">Overview</a> |
  <a href="#-installation">Installation</a> |
  <a href="#-example-usage">Examples</a> |
  <a href="#-key-features">Features</a> |
  <a href="docs/API_Reference.md" target="_blank">API Docs</a> |
  <a href="#-cli-usage">CLI</a>
</p>

## ğŸ“‹ Overview

Promptomatix is an AI-driven framework designed to automate and optimize large language model (LLM) prompts. It provides a structured approach to prompt optimization, ensuring consistency, cost-effectiveness, and high-quality outputs while reducing the trial-and-error typically associated with manual prompt engineering.

The framework leverages the power of DSPy and advanced optimization techniques to iteratively refine prompts based on task requirements, synthetic data, and user feedback. Whether you're a researcher exploring LLM capabilities or a developer building production applications, Promptomatix provides a comprehensive solution for prompt optimization.

**ğŸ“š API Documentation**: Comprehensive API documentation is available in the [`docs/`](docs/) directory, including detailed reference guides for all modules and functions.

## ğŸ—ï¸ Architecture

<div align="center">
  <a href="images/architecture1.pdf" target="_blank">
    <img src="images/architecture1_quality.png" alt="Promptomatix Architecture" width="1200"/>
  </a>
</div>

The Promptomatix architecture consists of several key components:

- **Input Processing**: Analyzes raw user input to determine task type and requirements
- **Synthetic Data Generation**: Creates training and testing datasets tailored to the specific task
- **Optimization Engine**: Uses DSPy or meta-prompt backends to iteratively improve prompts
- **Evaluation System**: Assesses prompt performance using task-specific metrics
- **Feedback Integration**: Incorporates human feedback for continuous improvement
- **Session Management**: Tracks optimization progress and maintains detailed logs

### ğŸŒŸ Key Features

- **Zero-Configuration Intelligence**: Automatically analyzes tasks, selects techniques, and configures prompts
- **Automated Dataset Generation**: Creates synthetic training and testing data tailored to your specific domain
- **Task-Specific Optimization**: Selects the appropriate DSPy module and metrics based on task type
- **Real-Time Human Feedback**: Incorporates user feedback for iterative prompt refinement
- **Comprehensive Session Management**: Tracks optimization progress and maintains detailed logs
- **Framework Agnostic Design**: Supports multiple LLM providers (OpenAI, Anthropic, Cohere)
- **CLI and API Interfaces**: Flexible usage through command-line or REST API

## âš™ï¸ Installation

### Quick Install (Recommended)

```bash
# Clone the repository
git clone https://github.com/airesearch-emu/promptomatix.git
cd promptomatix

# Install with one command
./install.sh
```

The installer will:
- âœ… Install [uv](https://docs.astral.sh/uv/) (if not already installed)
- âœ… Initialize git submodules (DSPy)
- âœ… Create a virtual environment (`.venv`) and install all dependencies via `uv sync`
- âœ… Download required NLTK data

### Manual Installation

If you prefer to install manually without the script:

```bash
# Install uv (if not installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Initialize git submodules
git submodule update --init --recursive

# Install all dependencies
uv sync
```

### ğŸ”‘ Set Up API Keys

```bash
# Create a .env file from the example
cp .env.example .env
# Edit .env with your actual API keys
```

### ğŸš€ Test Installation

```bash
# Test the installation
uv run promtomatic --raw_input "Given a questions about human anatomy answer it in two words" --model_name "gpt-3.5-turbo" --backend "simple_meta_prompt" --synthetic_data_size 10 --model_provider "openai"
```

### ğŸ’¡ Pro Tips

**Running commands**: Prefix commands with `uv run` to automatically use the project's virtual environment:
```bash
uv run promtomatic --help
uv run python -m src.promptomatix.main --help
```

**Activating the environment** (optional, if you prefer not to use `uv run`):
```bash
source .venv/bin/activate
```

## ğŸš€ Example Usage

### Interactive Notebooks

The best way to learn Promptomatix is through our comprehensive Jupyter notebooks:

```bash
# Navigate to examples
cd examples/notebooks

# Start with basic usage
jupyter notebook 01_basic_usage.ipynb
```

**Notebook Guide:**
- **`01_basic_usage.ipynb`** - Simple prompt optimization workflow (start here!)
- **`02_prompt_optimization.ipynb`** - Advanced optimization techniques
- **`03_metrics_evaluation.ipynb`** - Evaluation and metrics analysis
- **`04_advanced_features.ipynb`** - Advanced features and customization

### Command Line Examples

```bash
# Basic optimization
python -m src.promptomatix.main --raw_input "Classify text sentiment into positive or negative"

# With custom model and parameters
python -m src.promptomatix.main --raw_input "Summarize this article" \
  --model_name "gpt-4" \
  --temperature 0.3 \
  --task_type "summarization"
# Advanced configuration
python -m src.promptomatix.main --raw_input "Given a questions about human anatomy answer it in two words" \
  --model_name "gpt-3.5-turbo" \
  --backend "simple_meta_prompt" \
  --synthetic_data_size 10 \
  --model_provider "openai"

# Using your own CSV data files
python -m src.promptomatix.main --raw_input "Classify the given IMDb rating" \
  --model_name "gpt-3.5-turbo" \
  --backend "simple_meta_prompt" \
  --model_provider "openai" \
  --load_data_local \
  --local_train_data_path "/path/to/your/train_data.csv" \
  --local_test_data_path "/path/to/your/test_data.csv" \
  --train_data_size 50 \
  --valid_data_size 20 \
  --input_fields rating \
  --output_fields category
```

### Python API Examples

```python
from promptomatix import process_input, generate_feedback, optimize_with_feedback

# Basic optimization
result = process_input(
    raw_input="Classify text sentiment",
    model_name="gpt-3.5-turbo",
    task_type="classification"
)

# Generate feedback for improvement
feedback = generate_feedback(
    optimized_prompt=result['result'],
    input_fields=result['input_fields'],
    output_fields=result['output_fields'],
    model_name="gpt-3.5-turbo"
)

# Optimize with feedback
improved_result = optimize_with_feedback(result['session_id'])

# Using your own CSV data files
result = process_input(
    raw_input="Classify the given IMDb rating",
    model_name="gpt-3.5-turbo",
    backend="simple_meta_prompt",
    model_provider="openai",
    load_data_local=True,
    local_train_data_path="/path/to/your/train_data.csv",
    local_test_data_path="/path/to/your/test_data.csv",
    train_data_size=50,
    valid_data_size=20,
    input_fields=["rating"],
    output_fields=["category"]
)
```
#### ğŸ“ Project Structure

```
promptomatix/
â”œâ”€â”€ images/                # Project images and logos
â”œâ”€â”€ libs/                  # External libraries or submodules (e.g., DSPy)
â”œâ”€â”€ logs/                  # Log files
â”œâ”€â”€ sessions/              # Saved optimization sessions
â”œâ”€â”€ examples/              # Example notebooks and scripts
â”œâ”€â”€ src/
â”‚   â””â”€â”€ promptomatix/      # Core Python package
â”‚       â”œâ”€â”€ cli/
â”‚       â”œâ”€â”€ core/
â”‚       â”œâ”€â”€ metrics/
â”‚       â”œâ”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ lm_manager.py
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitmodules
â”œâ”€â”€ .python-version
â”œâ”€â”€ CODEOWNERS
â”œâ”€â”€ CODE_OF_CONDUCT.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ how_to_license.md
â”œâ”€â”€ install.sh
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ setup.py
```
---

## ğŸ“– Citation

If you find Promptomatix useful in your research or work, please consider citing us:

```bibtex
@misc{murthy2025promptomatixautomaticpromptoptimization,
      title={Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models}, 
      author={Rithesh Murthy and Ming Zhu and Liangwei Yang and Jielin Qiu and Juntao Tan and Shelby Heinecke and Caiming Xiong and Silvio Savarese and Huan Wang},
      year={2025},
      eprint={2507.14241},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.14241}, 
}
```
---

## ğŸ“š Further Reading

For detailed guidelines on effective prompt engineering, please refer to **Appendix B (page 17)** of our paper:

- [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)

## ğŸ“¬ Contact

For questions, suggestions, or contributions, please contact:

**Rithesh Murthy**  
Email: [rithesh.murthy@salesforce.com](mailto:rithesh.murthy@salesforce.com)

